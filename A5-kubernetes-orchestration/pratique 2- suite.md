# 1 - Introduction

Dans cet atelier pratique, vous allez apprendre les concepts de base de Kubernetes. Vous y parviendrez en interagissant avec Kubernetes via les terminaux de commande √† droite. En fin de compte, vous d√©ployerez les applications d'exemple Dockercoins sur les deux n≈ìuds de travail.

## D√©marrage

### Que sont ces terminaux dans les navigateurs ?

Sur votre droite, vous devriez voir deux fen√™tres de terminal. Il se peut qu'on vous demande de vous connecter d'abord, ce que vous pouvez faire soit avec un identifiant Docker soit avec un compte GitHub. Ces terminaux sont des terminaux enti√®rement fonctionnels ex√©cutant Centos. En fait, ce sont les lignes de commande pour des conteneurs Centos qui tournent sur notre infrastructure Play-with-Kubernetes. Lorsque vous voyez des blocs de code qui ressemblent √† cela, vous pouvez soit cliquer dessus et ils se rempliront automatiquement, soit vous pouvez les copier et les coller.

```
ls
```

### D√©marrer le cluster

La premi√®re √©tape consiste √† initialiser le cluster dans le premier terminal :

```
kubeadm init --apiserver-advertise-address $(hostname -i)
```

Cela prendra quelques minutes, pendant lesquelles vous verrez beaucoup d'activit√© dans le terminal.

Vous verrez quelque chose comme cela √† la fin :

```
Votre ma√Ætre Kubernetes a √©t√© initialis√© avec succ√®s !

Pour commencer √† utiliser votre cluster, vous devez ex√©cuter (en tant qu'utilisateur r√©gulier) :

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Vous devriez maintenant d√©ployer un r√©seau de pod dans le cluster.
Ex√©cutez "kubectl apply -f [podnetwork].yaml" avec une des options list√©es √† :
  http://kubernetes.io/docs/admin/addons/

Vous pouvez maintenant rejoindre n'importe quel nombre de machines en ex√©cutant la commande suivante sur chaque n≈ìud en tant que root :

kubeadm join --token SOMETOKEN SOMEIPADDRESS --discovery-token-ca-cert-hash SOMESHAHASH
```

Copiez toute la ligne qui commence par kubeadm join du premier terminal et collez-la dans le second terminal. Vous devriez voir quelque chose comme cela :

```
kubeadm join --token a146c9.9421a0d62a0611f4 172.26.0.2:6443 --discovery-token-ca-cert-hash sha256:9a4dc07bd8ac596336ecee6ce0928b3500174037c07a38a03bebef25e97c4db5
Initialisation de l'ID machine √† partir d'un g√©n√©rateur al√©atoire.
[kubeadm] ATTENTION : kubeadm est en b√™ta, veuillez ne pas l'utiliser pour des clusters de production.
[preflight] Passage des v√©rifications pr√©alables
[discovery] Tentative de connexion au serveur API "172.26.0.2:6443"
[discovery] Client de d√©couverte d'informations du cluster cr√©√©, demande d'infos √† "https://172.26.0.2:6443"
[discovery] Demande d'infos √† "https://172.26.0.2:6443" √† nouveau pour valider le TLS contre la cl√© publique √©pingl√©e
[discovery] La signature et le contenu des infos du cluster sont valides et le certificat TLS valide contre les racines √©pingl√©es, utilisera le serveur API "172.26.0.2:6443"
[discovery] Connexion √©tablie avec succ√®s avec le serveur API "172.26.0.2:6443"
[bootstrap] Version du serveur d√©tect√©e : v1.8.11
[bootstrap] Le serveur prend en charge l'API Certificates (certificates.k8s.io/v1beta1)

Jointure du n≈ìud compl√®te :
* Demande de signature de certificat envoy√©e au ma√Ætre et r√©ponse re√ßue.
* Kubelet inform√© des nouveaux d√©tails de connexion s√©curis√©e.

Ex√©cutez 'kubectl get nodes' sur le ma√Ætre pour voir cette machine rejoindre.
```

Cela signifie que vous √™tes presque pr√™t √† partir. Enfin, vous devez

 juste initialiser votre r√©seau de cluster dans le premier terminal :

```
kubectl apply -n kube-system -f \
 "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 |tr -d '\n')"
```

Vous verrez une sortie comme celle-ci :

```
kubectl apply -n kube-system -f \
>     "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 |tr -d '\n')"
serviceaccount "weave-net" cr√©√©
clusterrole "weave-net" cr√©√©
clusterrolebinding "weave-net" cr√©√©
role "weave-net" cr√©√©
rolebinding "weave-net" cr√©√©
daemonset "weave-net" cr√©√©
```

Votre cluster est configur√© !

### Quelle est cette application ?

C'est un mineur DockerCoin ! üí∞üê≥üì¶üö¢

Non, vous ne pouvez pas acheter de caf√© avec des DockerCoins

Comment fonctionnent les DockerCoins :

- Le travailleur demande √† rng de g√©n√©rer quelques octets al√©atoires
- Le travailleur nourrit ces octets dans hasher
- Et r√©p√®te √† l'infini !
- Chaque seconde, le travailleur met √† jour redis pour indiquer combien de boucles ont √©t√© faites
- webui interroge redis, et calcule et expose la "vitesse de hachage" dans votre navigateur

### Obtenir le code source de l'application

Nous avons cr√©√© une application d'exemple √† ex√©cuter pour des parties de l'atelier. L'application se trouve dans le d√©p√¥t dockercoins.

Jetons un coup d'≈ìil √† la disposition g√©n√©rale du code source :

- il y a un fichier Compose docker-compose.yml ‚Ä¶
- ‚Ä¶ et 4 autres services, chacun dans son propre r√©pertoire :
  - rng = service web g√©n√©rant des octets al√©atoires
  - hasher = service web calculant le hash des donn√©es POST√©es
  - worker = processus en arri√®re-plan utilisant rng et hasher
  - webui = interface web pour suivre les progr√®s

Nous allons cloner le d√©p√¥t GitHub

Le d√©p√¥t contient √©galement des scripts et des outils que nous utiliserons tout au long de l'atelier

```
git clone https://github.com/dockersamples/dockercoins
```

(Vous pouvez √©galement fork le d√©p√¥t sur GitHub et cloner votre fork si vous pr√©f√©rez cela.)

### Ex√©cuter l'application

Allez dans le r√©pertoire dockercoins, dans le d√©p√¥t clon√© :

```
cd ~/dockercoins
```

Utilisez Compose pour construire et lancer tous les conteneurs :

```
docker-compose up
```

Compose indique √† Docker de construire toutes les images de conteneur (en t√©l√©chargeant les images de base correspondantes), puis d√©marre tous les conteneurs et affiche les logs agr√©g√©s.

#### Beaucoup de logs

L'application g√©n√®re continuellement des logs

Nous pouvons voir le service worker faire des requ√™tes √† rng et √† hasher

Mettons cela en arri√®re-plan

### Se connecter √† l'interface web

Le conteneur webui expose un tableau de bord web ; voyons-le

Avec un navigateur web, connectez-vous √† node1 ici sur le port 8000 (cr√©√© lorsque vous avez ex√©cut√© l'application)

### Nettoyage

Avant de continuer, √©teignons tout en tapant Ctrl-C.

# 2 - Concepts #1 de Kubernetes 

## Introduction √† Kubernetes

Kubernetes est un syst√®me de gestion de conteneurs qui permet de d√©ployer, de g√©rer et d'orchestrer des applications conteneuris√©es sur un cluster. Mais que signifie r√©ellement cette d√©finition ?

### Qu'est-ce que Kubernetes ?

- **Syst√®me de gestion de conteneurs :** Kubernetes vous permet de g√©rer des applications qui sont divis√©es en conteneurs, en s'assurant qu'ils s'ex√©cutent l√† o√π et quand vous le souhaitez.
- **Cluster :** Les conteneurs sont ex√©cut√©s sur un ensemble de machines appel√© cluster. Ce cluster peut √™tre sur site ou dans le cloud.

### Actions de base avec Kubernetes

Avec Kubernetes, vous pouvez demander de :

- **D√©marrer des conteneurs :** Par exemple, lancer 5 conteneurs utilisant l'image `atseashop/api:v1.3`.
- **Balancer la charge :** Placer un √©quilibreur de charge interne devant ces conteneurs ou un √©quilibreur de charge public devant 10 conteneurs utilisant l'image `atseashop/webfront:v1.3`.
- **G√©rer le trafic :** Augmenter la capacit√© de votre cluster lors de pics de trafic, comme le Black Friday.
- **Mettre √† jour des applications :** Remplacer vos conteneurs par de nouveaux utilisant une image mise √† jour, par exemple `atseashop/webfront:v1.4`, tout en continuant de traiter les requ√™tes.

### Capacit√©s avanc√©es de Kubernetes

Kubernetes ne s'arr√™te pas l√†. Il peut √©galement :

- **Mettre √† l'√©chelle automatiquement :** Ajuster le nombre de conteneurs en fonction de la charge.
- **D√©ploiement blue/green et canary :** Tester de nouvelles versions d'applications sans impact sur les utilisateurs actuels (https://circleci.com/blog/canary-vs-blue-green-downtime/#:~:text=In%20blue%2Dgreen%20deployment%20you,first%2C%20before%20finishing%20the%20others)
- Dans le d√©ploiement blue-green, vous servez l'application actuelle sur une moiti√© de votre environnement (Bleu) et d√©ployez votre nouvelle application sur l'autre moiti√© (Vert) sans affecter l'environnement bleu. Dans le d√©ploiement canari, vous basculez juste un petit sous-ensemble de serveurs ou de n≈ìuds en premier, avant de terminer avec les autres.
  
- **G√©rer des t√¢ches de longue dur√©e et des jobs ponctuels :** Ex√©cuter des services persistants ainsi que des t√¢ches qui ne doivent s'ex√©cuter qu'une seule fois.
- **Surdimensionner et √©vincer les t√¢ches de faible priorit√© :** Utiliser pleinement les ressources du cluster tout en g√©rant les priorit√©s entre t√¢ches.
- **Ex√©cuter des services avec des donn√©es √† √©tat :** G√©rer des bases de donn√©es et d'autres types de services n√©cessitant un stockage persistant.
- **Contr√¥le d'acc√®s d√©taill√© :** D√©finir qui peut faire quoi au sein du cluster.
- **Int√©grer des services tiers :** Utiliser des services externes comme s'ils faisaient partie de votre cluster.
- **Automatiser des t√¢ches complexes :** Utiliser des op√©rateurs pour g√©rer des applications de mani√®re plus sophistiqu√©e.

## R√©sum√© des concepts #1 de Kubernetes



# 3- L'Architecture de Kubernetes #1 (introduction)

## Encore et encore un rappel Kubernetes

Avant de plonger dans l'architecture de Kubernetes, comprenons ce qu'est Kubernetes. Kubernetes est un syst√®me open-source pour automatiser le d√©ploiement, la mise √† l'√©chelle et la gestion des applications conteneuris√©es. Il vous aide √† g√©rer des applications complexes avec efficacit√© et flexibilit√©.

## Architecture de Kubernetes

L'architecture de Kubernetes est divis√©e en deux parties principales : le ma√Ætre (master) et les n≈ìuds (nodes).

### Le Ma√Ætre Kubernetes

Le "ma√Ætre" est le cerveau derri√®re l'op√©ration de Kubernetes. Il prend des d√©cisions globales sur le cluster (comme le lancement de nouveaux conteneurs) et d√©tecte et r√©pond aux √©v√©nements du cluster (comme le crash d'un conteneur). Les composants cl√©s du ma√Ætre incluent :

- **API Server :** Le point d'entr√©e dans Kubernetes, permettant la communication entre les diff√©rents services.
- **Scheduler :** D√©cide sur quel n≈ìud lancer les nouveaux conteneurs bas√©s sur la disponibilit√© des ressources.
- **Controller Manager :** G√®re un ensemble de contr√¥leurs qui r√©gulent l'√©tat du cluster.
- **etcd :** Un magasin cl√©/valeur hautement disponible qui stocke toutes les donn√©es du cluster, agissant comme la base de donn√©es de Kubernetes.

Ces services peuvent s'ex√©cuter directement sur une machine h√¥te ou dans des conteneurs. Il est possible d'avoir plusieurs ma√Ætres pour une haute disponibilit√©.

### Les N≈ìuds Kubernetes

Les n≈ìuds sont les machines (physiques ou virtuelles) qui ex√©cutent vos applications et workloads Kubernetes. Chaque n≈ìud contient les services n√©cessaires pour ex√©cuter des conteneurs, notamment :

- **Moteur de conteneur (Docker, par exemple) :** Pour ex√©cuter les conteneurs.
- **Kubelet :** Un agent qui s'assure que les conteneurs s'ex√©cutent dans un Pod.
- **Kube-proxy :** G√®re le r√©seau des conteneurs, y compris l'√©quilibrage de charge.

Il est courant de ne pas ex√©cuter d'applications sur les n≈ìuds qui ex√©cutent les composants du ma√Ætre, sauf dans le cas de petits clusters de d√©veloppement.

## Conclusion

Comprendre l'architecture de Kubernetes est essentiel pour g√©rer efficacement les applications conteneuris√©es √† grande √©chelle. Avec son architecture ma√Ætre/n≈ìud, Kubernetes offre une plateforme robuste et flexible pour d√©ployer, √©chelonner et g√©rer vos applications dans un environnement de cloud.


# 4- L'Architecture de Kubernetes #2 - c√¥t√© ma√Ætre (en d√©tail)

Explorons en d√©tail les composants du ma√Ætre Kubernetes pour comprendre leur r√¥le et leur fonctionnement au sein de l'architecture de Kubernetes, sans r√©p√©ter les informations d√©j√† fournies.

### API Server

Le serveur API agit comme la porte d'entr√©e pour toutes les op√©rations de gestion du cluster Kubernetes. C'est par ce canal que les requ√™tes sont envoy√©es, que ce soit pour cr√©er de nouveaux pods, g√©rer les ressources existantes ou interroger l'√©tat du syst√®me. Cette interface RESTful assure que les utilisateurs, les services internes de Kubernetes, et les composants externes peuvent communiquer de mani√®re s√©curis√©e et efficace. Le serveur API est con√ßu pour √™tre l'unique point de convergence pour la logique d'orchestration, garantissant que toutes les modifications de l'√©tat du cluster passent par un processus de validation et d'autorisation uniforme.

### Scheduler

Le planificateur, ou scheduler, est charg√© de l'attribution des pods aux n≈ìuds. Il analyse l'√©tat actuel du cluster, y compris la consommation des ressources par chaque n≈ìud, et prend des d√©cisions √©clair√©es sur l'endroit o√π d√©ployer les nouveaux pods en fonction des exigences de ressources et des contraintes sp√©cifi√©es. Ce processus assure une distribution optimale des charges de travail √† travers le cluster, am√©liorant ainsi l'efficacit√© et la performance globale du syst√®me. Le scheduler peut √™tre personnalis√© pour r√©pondre √† des politiques de planification sp√©cifiques, permettant aux administrateurs de prioriser certains types de charges de travail ou d'adapter le comportement du planificateur aux besoins de leur environnement.

### Controller Manager

Le gestionnaire de contr√¥leurs supervise une vari√©t√© de contr√¥leurs qui r√©gulent l'√©tat d√©sir√© du cluster Kubernetes. Chaque contr√¥leur est responsable d'une facette particuli√®re de l'√©tat global du cluster, comme la gestion des r√©plicas de pods, la gestion des n≈ìuds, ou la gestion des endpoints. En surveillant en continu l'√©tat du cluster et en effectuant des ajustements selon les besoins, le Controller Manager joue un r√¥le cl√© dans l'auto-r√©paration et la gestion des configurations d√©claratives. Cette composante assure que l'√©tat r√©el du cluster correspond √† l'√©tat d√©sir√© sp√©cifi√© par l'utilisateur, traitant les √©v√©nements tels que les d√©faillances de n≈ìuds ou les modifications de configuration.

### etcd

etcd est le stockage de donn√©es distribu√© qui sert de pierre angulaire pour la coh√©rence de l'√©tat du cluster Kubernetes. En tant que base de donn√©es cl√©/valeur, etcd m√©morise l'√©tat de configuration, le statut, et les m√©tadonn√©es essentielles de toutes les ressources Kubernetes. Gr√¢ce √† sa haute disponibilit√© et sa tol√©rance aux pannes, etcd permet √† Kubernetes de r√©cup√©rer rapidement de d√©faillances du ma√Ætre, en garantissant qu'aucune donn√©e essentielle n'est perdue et que l'√©tat du cluster peut √™tre restaur√© √† un √©tat coh√©rent. Le choix d'etcd comme magasin de donn√©es refl√®te l'importance de la fiabilit√©, de la performance, et de la coh√©rence des donn√©es dans la gestion des environnements distribu√©s complexes.

Chacun de ces composants joue un r√¥le crucial dans la gestion du cluster Kubernetes, travaillant ensemble pour offrir une plateforme robuste, √©volutive et hautement disponible pour d√©ployer et g√©rer des applications conteneuris√©es √† grande √©chelle.


# 5- L'Architecture de Kubernetes #3 - c√¥t√© worker (en d√©tail - 3 composants cl√©s)

Approfondissons le c√¥t√© travailleur (worker) dans l'architecture Kubernetes, en mettant l'accent sur les composants essentiels qui facilitent l'ex√©cution et la gestion des conteneurs au sein d'un n≈ìud de travail.

### Container Runtime

Le moteur d'ex√©cution de conteneurs est le fondement qui permet √† Kubernetes de lancer et de g√©rer les conteneurs sur chaque n≈ìud. Ce composant cr√©e un environnement isol√© pour chaque conteneur, s'occupant de l'ex√©cution du code de l'application, de la gestion des ressources syst√®me attribu√©es (comme la CPU, la m√©moire, et le stockage), et de l'isolation du r√©seau. Kubernetes est compatible avec plusieurs moteurs d'ex√©cution de conteneurs, y compris Docker, containerd, et CRI-O, offrant aux utilisateurs la flexibilit√© de choisir la technologie qui convient le mieux √† leurs besoins sp√©cifiques. Cette couche d'abstraction assure que les applications s'ex√©cutent de mani√®re coh√©rente, ind√©pendamment de l'environnement sous-jacent.

### Kubelet

Kubelet agit comme un agent sur chaque n≈ìud, communiquant directement avec le serveur API du ma√Ætre pour recevoir les instructions et envoyer des rapports d'√©tat. Il s'assure que les conteneurs d√©ploy√©s dans les pods sont en cours d'ex√©cution et en bonne sant√©, conform√©ment aux sp√©cifications d√©finies dans les objets Pod. Si un conteneur √©choue ou s'arr√™te, le Kubelet prend les mesures n√©cessaires pour red√©marrer le conteneur et maintenir l'√©tat d√©sir√© sp√©cifi√©. En surveillant en permanence l'√©tat des pods et en ex√©cutant les actions requises, le Kubelet joue un r√¥le crucial dans l'auto-gu√©rison et la gestion des t√¢ches au niveau du n≈ìud.

### Kube-proxy

Kube-proxy est un composant r√©seau cl√© qui s'ex√©cute sur chaque n≈ìud, facilitant la communication r√©seau √† l'int√©rieur et √† l'ext√©rieur du cluster Kubernetes. Il g√®re l'acc√®s aux services en redirigeant le trafic r√©seau vers les conteneurs appropri√©s, en utilisant des r√®gles de routage IP et des ports. Kube-proxy permet ainsi d'√©quilibrer la charge entre plusieurs instances d'une application, am√©liorant la disponibilit√© et la performance des services. En manipulant les r√®gles de r√©seau sur les n≈ìuds, kube-proxy assure que la communication entre les conteneurs, ainsi que celle entre les conteneurs et l'ext√©rieur du cluster, est fluide et s√©curis√©e.

Ces trois composants travaillent de concert pour garantir que les applications conteneuris√©es sur les n≈ìuds de travail fonctionnent comme pr√©vu. Ils offrent une couche d'orchestration qui prend en charge la gestion du cycle de vie des conteneurs, la mise en r√©seau, et la communication avec le reste du cluster. Ensemble, ils permettent √† Kubernetes de fournir une plateforme r√©siliente, performante et facile √† g√©rer pour d√©ployer des applications √† grande √©chelle.

